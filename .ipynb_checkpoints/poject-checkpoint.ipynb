{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNIST(path='data/', return_type='numpy')\n",
    "data.select_emnist('letters')\n",
    "X , y = data.load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124800, 784), (124800,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(124800, 28, 28)\n",
    "y = y.reshape(124800, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y-1\n",
    "#list ranges from 0 to 25 now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. traing-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0,255) --> (0,1)\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow\n",
    "# integer into one hot vector (binary class matrix)\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train, num_classes = 26)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes = 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape = (28,28)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2)) # preventing overfitting\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(26, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 677,914\n",
      "Trainable params: 677,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, test accuracy is 3.0608974397182465\n"
     ]
    }
   ],
   "source": [
    "# before training\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print(\"Before training, test accuracy is\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's train our model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "622/624 [============================>.] - ETA: 0s - loss: 0.7939 - accuracy: 0.7593\n",
      "Epoch 00001: val_loss improved from inf to 0.44712, saving model to best_model.h5\n",
      "624/624 [==============================] - 42s 68ms/step - loss: 0.7931 - accuracy: 0.7596 - val_loss: 0.4471 - val_accuracy: 0.8580\n",
      "Epoch 2/10\n",
      "622/624 [============================>.] - ETA: 0s - loss: 0.4220 - accuracy: 0.8649\n",
      "Epoch 00002: val_loss improved from 0.44712 to 0.34126, saving model to best_model.h5\n",
      "624/624 [==============================] - 9s 14ms/step - loss: 0.4219 - accuracy: 0.8649 - val_loss: 0.3413 - val_accuracy: 0.8913\n",
      "Epoch 3/10\n",
      "623/624 [============================>.] - ETA: 0s - loss: 0.3399 - accuracy: 0.8880\n",
      "Epoch 00003: val_loss improved from 0.34126 to 0.31669, saving model to best_model.h5\n",
      "624/624 [==============================] - 9s 14ms/step - loss: 0.3399 - accuracy: 0.8881 - val_loss: 0.3167 - val_accuracy: 0.8992\n",
      "Epoch 4/10\n",
      "624/624 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.9013\n",
      "Epoch 00004: val_loss improved from 0.31669 to 0.29772, saving model to best_model.h5\n",
      "624/624 [==============================] - 9s 14ms/step - loss: 0.2942 - accuracy: 0.9013 - val_loss: 0.2977 - val_accuracy: 0.9028\n",
      "Epoch 5/10\n",
      "624/624 [==============================] - ETA: 0s - loss: 0.2642 - accuracy: 0.9105\n",
      "Epoch 00005: val_loss improved from 0.29772 to 0.28960, saving model to best_model.h5\n",
      "624/624 [==============================] - 9s 14ms/step - loss: 0.2642 - accuracy: 0.9105 - val_loss: 0.2896 - val_accuracy: 0.9076\n",
      "Epoch 6/10\n",
      "622/624 [============================>.] - ETA: 0s - loss: 0.2402 - accuracy: 0.9168\n",
      "Epoch 00006: val_loss improved from 0.28960 to 0.28275, saving model to best_model.h5\n",
      "624/624 [==============================] - 9s 14ms/step - loss: 0.2402 - accuracy: 0.9168 - val_loss: 0.2827 - val_accuracy: 0.9109\n",
      "Epoch 7/10\n",
      "622/624 [============================>.] - ETA: 0s - loss: 0.2223 - accuracy: 0.9209\n",
      "Epoch 00007: val_loss did not improve from 0.28275\n",
      "624/624 [==============================] - 9s 14ms/step - loss: 0.2222 - accuracy: 0.9209 - val_loss: 0.2879 - val_accuracy: 0.9086\n",
      "Epoch 8/10\n",
      "623/624 [============================>.] - ETA: 0s - loss: 0.2050 - accuracy: 0.9270\n",
      "Epoch 00008: val_loss improved from 0.28275 to 0.28186, saving model to best_model.h5\n",
      "624/624 [==============================] - 9s 14ms/step - loss: 0.2050 - accuracy: 0.9270 - val_loss: 0.2819 - val_accuracy: 0.9146\n",
      "Epoch 9/10\n",
      "621/624 [============================>.] - ETA: 0s - loss: 0.1921 - accuracy: 0.9303\n",
      "Epoch 00009: val_loss did not improve from 0.28186\n",
      "624/624 [==============================] - 9s 14ms/step - loss: 0.1919 - accuracy: 0.9304 - val_loss: 0.2837 - val_accuracy: 0.9131\n",
      "Epoch 10/10\n",
      "621/624 [============================>.] - ETA: 0s - loss: 0.1811 - accuracy: 0.9338\n",
      "Epoch 00010: val_loss improved from 0.28186 to 0.27629, saving model to best_model.h5\n",
      "624/624 [==============================] - 9s 14ms/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.2763 - val_accuracy: 0.9163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24bf5a75d90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath = 'best_model.h5', verbose=1, save_best_only = True)\n",
    "model.fit(X_train, y_train, batch_size = 128, epochs= 10, validation_split = 0.2, \n",
    "          callbacks=[checkpointer], verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is  91.26602411270142\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy is \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters ={ 0:'a', 1:'b', 2:'c', 3:'d', 4:'e', 5:'f', 6:'g', 7:'h', 8:'i', 9:'j', 10:'k', 11:'l', \n",
    "          12:'m', 13:'n', 14:'o', 15:'p', 16:'q', 17:'r', 18:'s', 19:'t', 20:'u', 21:'v', 22:'w', \n",
    "          23:'x', 24:'y', 25:'z', 26:''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining blue color in hsv format\n",
    "# pip install numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blueLower = np.array([100,60,60])\n",
    "blueUpper = np.array([140,255,255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define blackboard\n",
    "blackboard = np.zeros((480,640, 3), dtype=np.uint8)\n",
    "alphabet = np.zeros((200,200,3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deques (Double ended queue) is used to store alphabet drawn on screen\n",
    "from collections import deque\n",
    "points = deque(maxlen = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### open the camera and recognize alphabet\n",
    "\n",
    "import cv2 #pip install opencv-python\n",
    "cap = cv2.VideoCapture(0)\n",
    "prediction = 26\n",
    "while True:\n",
    "    ret, frame=cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detecting which pixel value falls under blue color boundaries\n",
    "    blue = cv2.inRange(hsv, blueLower, blueUpper)\n",
    "    \n",
    "    #erosion\n",
    "    blue = cv2.erode(blue, kernel)\n",
    "    #opening\n",
    "    blue = cv2.morphologyEx(blue, cv2.MORPH_OPEN, kernel)\n",
    "    #dilation\n",
    "    blue = cv2.dilate(blue, kernel)\n",
    "    \n",
    "    # find countours in the image\n",
    "    cnts , _ = cv2.findContours(blue, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "     \n",
    "    center = None\n",
    "    \n",
    "    # if any countours were found\n",
    "    if len(cnts) > 0:\n",
    "        cnt = sorted(cnts, key = cv2.contourArea, reverse=True)[0]\n",
    "        ((x,y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "        cv2.circle(frame, (int(x), int(y),), int(radius), (125,344,278), 2)\n",
    "        \n",
    "        M = cv2.moments(cnt)\n",
    "        center = (int(M['m10']/M['m00']), int(M['m01']/M['m00']))\n",
    "    \n",
    "        points.appendleft(center)\n",
    "        \n",
    "    elif len(cnts) == 0:\n",
    "        if len(points) != 0:\n",
    "            blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "            blur = cv2.medianBlur(blackboard_gray, 15)\n",
    "            blur = cv2.GaussianBlur(blur, (5,5), 0)\n",
    "            thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "            #cv2.imshow(\"Thresh\", thresh)\n",
    "            \n",
    "            blackboard_cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[0]\n",
    "            \n",
    "            if len(blackboard_cnts)>=1:\n",
    "                cnt = sorted(blackboard_cnts, key=cv2.contourArea, reverse=True)[0]\n",
    "                \n",
    "                if cv2.contourArea(cnt)>1000:\n",
    "                    x,y,w,h = cv2.boundingRect(cnt)\n",
    "                    alphabet = blackboard_gray[y-10:y+h+10,x-10:x+w+10]\n",
    "                    try:\n",
    "                        img = cv2.resize(alphabet, (28,28))\n",
    "                    except cv2.error as e:\n",
    "                        continue\n",
    "                    \n",
    "                    img = np.array(img)\n",
    "                    img = img.astype('float32')/255\n",
    "                     \n",
    "                        \n",
    "                    prediction = model.predict(img.reshape(1,28,28))[0]\n",
    "                    prediction = np.argmax(prediction)\n",
    "                    \n",
    "            # Empty the point deque and also blackboard\n",
    "            points = deque(maxlen=512)\n",
    "            blackboard = np.zeros((480,640, 3), dtype=np.uint8)\n",
    "        \n",
    "    # connect the detected points with line\n",
    "    for i in range(1, len(points)):\n",
    "        if points[i-1] is None or points[i] is None:\n",
    "            continue\n",
    "        cv2.line(frame, points[i-1], points[i], (0,0,0), 2)\n",
    "        cv2.line(blackboard, points[i-1], points[i], (255,255,255), 8)\n",
    "        \n",
    "    \n",
    "    cv2.putText(frame, \"Prediction: \" + str(letters[int(prediction)]), (20,400), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Character Recognition System\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1)==13: #if I press enter\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
